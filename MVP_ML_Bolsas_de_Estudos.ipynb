{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGbp+Nr8SvFHEbUOTSz8fI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dev-alexandremarcet/mvp_ml_students/blob/main/MVP_ML_Bolsas_de_Estudos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MVP de Machine Learning - Alexandre Peixoto Marcet**\n",
        "\n",
        "  Este MVP é um modelo de machine learning de classificação. Ele faz a predição de um determinado aluno (ingressante numa faculdade particular) receber bolsa de estudos ou não."
      ],
      "metadata": {
        "id": "_o2iSn8pBp9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Definição do Problema\n",
        "\n",
        "O problema se resume em fazer a previsão se um aluno vai receber uma bolsa de estudos, considerando que esse aluno está ingressando numa determinada universidade privada. Essa previsão deverá ser feita a partir de algumas informações do aluno, tais como: renda per capita familiar, notas no vestibular, participação em programas sociais do governo e premiações em olimpíadas do conhecimento. Essas informações servem de base para o estabelecimento de critérios para a concessão de bolsas pela referida universidade privada.\n",
        "Os dados estão restritos a informações que não identificam os alunos. Essa foi a condição para a obtenção, uso e divulgação dos dados neste MVP.\n",
        "O dataset possui os seguintes atributos:\n",
        "\n",
        "[0] - num_inscricao-->número de inscrição do aluno no processo seletivo para concessão de bolsas de estudo\n",
        "\n",
        "[1] - nota_mat-->nota do aluno na área de Matemática no vestibular\n",
        "\n",
        "[2] - nota_linguagens-->nota do aluno na área de Linguagens no vestibular\n",
        "\n",
        "[3] - nota_ciencias_hum-->nota do aluno na área de Ciências Humanas no vestibular\n",
        "\n",
        "[4] - nota_ciencias_nat-->nota do aluno na área de Ciências da Natureza no vestibular\n",
        "\n",
        "[5] - nota_redacao-->nota do aluno em redação no vestibular\n",
        "\n",
        "[6] - renda_per_capita_fam-->renda per capita do núcleo familiar do aluno\n",
        "\n",
        "[7] - premio_olimp_cohecimento-->atributo para a verificação se o aluno recebeu premiação em qualquer olimpíada do conhecimento(1 se recebeu, 0 se não recebeu)\n",
        "\n",
        "[8] - prog_social_gov-->atributo para a verificação se o aluno (ou a família dele) participa de algum programa social de transferência de renda do governo(municipal,estadual ou federal) (1 se o aluno ou a família participa, 0 se não participa)\n"
      ],
      "metadata": {
        "id": "HHjp2z_RB-Ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Preparação dos Dados\n",
        "\n",
        "## 2.1 - Importação de modelos, classificadores, bibliotecas e algoritmos"
      ],
      "metadata": {
        "id": "PLdB6_xk8EKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração para não exibir os warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Imports necessários\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split # para particionar em bases de treino e teste (holdout)\n",
        "from sklearn.model_selection import KFold # para preparar os folds da validação cruzada\n",
        "from sklearn.model_selection import StratifiedKFold # para preparar os folds com estratificação\n",
        "from sklearn.model_selection import cross_val_score # para executar a validação cruzada\n",
        "from sklearn.metrics import accuracy_score # para a exibição da acurácia do modelo\n",
        "from sklearn.pipeline import Pipeline # para preparar os pipelines\n",
        "from sklearn.linear_model import LogisticRegression # algoritmo de Regressão Logística\n",
        "from sklearn.neighbors import KNeighborsClassifier # algoritmo KNN\n",
        "from sklearn.tree import DecisionTreeClassifier # algoritmo Árvore de Classificação\n",
        "from sklearn.naive_bayes import GaussianNB # algoritmo Naive Bayes\n",
        "from sklearn.svm import SVC # algoritmo SVM\n",
        "from sklearn.ensemble import ExtraTreesClassifier # ExtraTrees para a feature selection Importância de Atributos e ensemble Bagging\n",
        "from sklearn.ensemble import BaggingClassifier # para ensemble Bagging\n",
        "from sklearn.ensemble import RandomForestClassifier # para ensemble Bagging\n",
        "from sklearn.ensemble import VotingClassifier # para ensemble Voting\n",
        "from sklearn.ensemble import AdaBoostClassifier # para ensemble Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier # para ensemble Boosting"
      ],
      "metadata": {
        "id": "Bk5BCXX1C6k0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 - Carregamento do Dataset"
      ],
      "metadata": {
        "id": "8RILIacTNfY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Informa a URL de importação do dataset\n",
        "url = \"https://raw.githubusercontent.com/dev-alexandremarcet/mvp_ml_students/main/students-dataset.csv\"\n",
        "\n",
        "# Lê o arquivo\n",
        "dataset = pd.read_csv(url, delimiter=',')\n",
        "\n",
        "# Mostra as primeiras linhas do dataset\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "qDzDk16pDWy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 - Separação do dataset em conjunto de treino e conjunto de teste (usando holdout com estratificação) e fazendo a validação cruzada"
      ],
      "metadata": {
        "id": "NuWQ25y6NzjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparação dos dados\n",
        "test_size = 0.30 # definindo o tamanho do conjunto de teste\n",
        "seed = 7 # definindo a semente aleatória\n",
        "\n",
        "# Separação em conjuntos de treino e teste (holdout)\n",
        "array = dataset.values\n",
        "X = array[:,0:9] # atributos\n",
        "Y = array[:,9] # classe (recebe_bolsa)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, shuffle=True, random_state=seed, stratify=Y) # efetua a divisão dos dados em conjuntos de treino e teste (holdout)\n",
        "\n",
        "# Definindo parâmetros e criando os folds para a validação cruzada\n",
        "scoring = 'accuracy'\n",
        "num_particoes = 10 # número de folds da validação cruzada\n",
        "kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # faz o particionamento em 10 folds\n"
      ],
      "metadata": {
        "id": "QLEEtftQFcOK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 - Verificando a importância de atributos"
      ],
      "metadata": {
        "id": "LhmKRFQnOri1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criação do modelo para a seleção de atributos\n",
        "modelo = ExtraTreesClassifier(n_estimators=100)\n",
        "modelo.fit(X,Y)\n",
        "\n",
        "# Exibe os atributos originais\n",
        "print(\"\\Atributos Originais:\", dataset.columns[0:9])\n",
        "\n",
        "# Exibe a pontuação de importância para cada atributo\n",
        "print(modelo.feature_importances_)"
      ],
      "metadata": {
        "id": "n35mp03s63Ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observação: Como apenas dois atributos possuem valores maiores do que 0,11 (aproximadamente a média das pontuações), nenhum atributo foi descartado. Além disso, o número de atributos do dataset é bem pequeno."
      ],
      "metadata": {
        "id": "rPGmiPSTPVvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Modelagem e Treinamento\n",
        "\n",
        "## 3.1 - Criação de modelos básicos e *ensembles*\n"
      ],
      "metadata": {
        "id": "fB__y6tQCK_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelagem\n",
        "\n",
        "# Definindo uma seed global para esta célula de código\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Criando uma lista para armazenar os modelos\n",
        "models = []\n",
        "\n",
        "# Criando os modelos e adicionando-os na lista de modelos\n",
        "models.append(('LR', LogisticRegression(max_iter=200)))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "\n",
        "# Definindo os parâmetros do classificador base para o BaggingClassifier\n",
        "base = DecisionTreeClassifier()\n",
        "num_trees = 100\n",
        "max_features = 3\n",
        "\n",
        "# Criando os modelos para o VotingClassifier\n",
        "bases = []\n",
        "model1 = LogisticRegression(max_iter=200)\n",
        "bases.append(('logistic', model1))\n",
        "model2 = DecisionTreeClassifier()\n",
        "bases.append(('cart', model2))\n",
        "model3 = SVC()\n",
        "bases.append(('svm', model3))\n",
        "\n",
        "# Criando os ensembles e adicionando-os na lista de modelos\n",
        "models.append(('Bagging', BaggingClassifier(base_estimator=base, n_estimators=num_trees)))\n",
        "models.append(('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)))\n",
        "models.append(('Ada', AdaBoostClassifier(n_estimators=num_trees)))\n",
        "models.append(('GB', GradientBoostingClassifier(n_estimators=num_trees)))\n",
        "models.append(('Voting', VotingClassifier(bases)))"
      ],
      "metadata": {
        "id": "CgoGKjrFG-qB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observação: Foram criados modelos básicos e *ensembles* para disponibilizar mais modelos para treinamento, com o objetivo de resolver o problema usando o melhor modelo possível."
      ],
      "metadata": {
        "id": "0ePfp7xvS1yK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 - Avaliação dos modelos básicos e *ensembles*"
      ],
      "metadata": {
        "id": "swzDi8gOSZyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listas para armazenar os resultados\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "# Avaliando um modelo por vez\n",
        "for name, model in models:\n",
        "  cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "  results.append(cv_results)\n",
        "  names.append(name)\n",
        "  msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std()) # média e desvio padrão dos 10 resultados da validação cruzada\n",
        "  print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(15,10))\n",
        "fig.suptitle('Comparação da Acurácia dos Modelos')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xotb7O0ASSUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 - Criação de modelos com dados padronizados e com dados normalizados"
      ],
      "metadata": {
        "id": "cLCmbgsQUHrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7) # definindo uma semente global para este bloco\n",
        "\n",
        "# Listas para armazenar os armazenar os pipelines e os resultados para todas as visões do dataset\n",
        "pipelines = []\n",
        "results = []\n",
        "names = []\n",
        "\n",
        "\n",
        "# Criando os elementos do pipeline\n",
        "\n",
        "# Algoritmos que serão utilizados\n",
        "reg_log = ('LR', LogisticRegression(max_iter=200))\n",
        "knn = ('KNN', KNeighborsClassifier())\n",
        "cart = ('CART', DecisionTreeClassifier())\n",
        "naive_bayes = ('NB', GaussianNB())\n",
        "svm = ('SVM', SVC())\n",
        "bagging = ('Bag', BaggingClassifier(base_estimator=base, n_estimators=num_trees))\n",
        "random_forest = ('RF', RandomForestClassifier(n_estimators=num_trees, max_features=max_features))\n",
        "extra_trees = ('ET', ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features))\n",
        "adaboost = ('Ada', AdaBoostClassifier(n_estimators=num_trees))\n",
        "gradient_boosting = ('GB', GradientBoostingClassifier(n_estimators=num_trees))\n",
        "voting = ('Voting', VotingClassifier(bases))\n",
        "\n",
        "# Transformações que serão utilizadas\n",
        "standard_scaler = ('StandardScaler', StandardScaler())\n",
        "min_max_scaler = ('MinMaxScaler', MinMaxScaler())\n",
        "\n",
        "\n",
        "# Montando os pipelines\n",
        "\n",
        "# Dataset original\n",
        "pipelines.append(('LR-orig', Pipeline([reg_log])))\n",
        "pipelines.append(('KNN-orig', Pipeline([knn])))\n",
        "pipelines.append(('CART-orig', Pipeline([cart])))\n",
        "pipelines.append(('NB-orig', Pipeline([naive_bayes])))\n",
        "pipelines.append(('SVM-orig', Pipeline([svm])))\n",
        "pipelines.append(('Bag-orig', Pipeline([bagging])))\n",
        "pipelines.append(('RF-orig', Pipeline([random_forest])))\n",
        "pipelines.append(('ET-orig', Pipeline([extra_trees])))\n",
        "pipelines.append(('Ada-orig', Pipeline([adaboost])))\n",
        "pipelines.append(('GB-orig', Pipeline([gradient_boosting])))\n",
        "pipelines.append(('Vot-orig', Pipeline([voting])))\n",
        "\n",
        "# Dataset Padronizado\n",
        "pipelines.append(('LR-padr', Pipeline([standard_scaler, reg_log])))\n",
        "pipelines.append(('KNN-padr', Pipeline([standard_scaler, knn])))\n",
        "pipelines.append(('CART-padr', Pipeline([standard_scaler, cart])))\n",
        "pipelines.append(('NB-padr', Pipeline([standard_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-padr', Pipeline([standard_scaler, svm])))\n",
        "pipelines.append(('Bag-padr', Pipeline([standard_scaler, bagging])))\n",
        "pipelines.append(('RF-padr', Pipeline([standard_scaler, random_forest])))\n",
        "pipelines.append(('ET-padr', Pipeline([standard_scaler, extra_trees])))\n",
        "pipelines.append(('Ada-padr', Pipeline([standard_scaler, adaboost])))\n",
        "pipelines.append(('GB-padr', Pipeline([standard_scaler, gradient_boosting])))\n",
        "pipelines.append(('Vot-padr', Pipeline([standard_scaler, voting])))\n",
        "\n",
        "# Dataset Normalizado\n",
        "pipelines.append(('LR-norm', Pipeline([min_max_scaler, reg_log])))\n",
        "pipelines.append(('KNN-norm', Pipeline([min_max_scaler, knn])))\n",
        "pipelines.append(('CART-norm', Pipeline([min_max_scaler, cart])))\n",
        "pipelines.append(('NB-norm', Pipeline([min_max_scaler, naive_bayes])))\n",
        "pipelines.append(('SVM-norm', Pipeline([min_max_scaler, svm])))\n",
        "pipelines.append(('Bag-norm', Pipeline([min_max_scaler, bagging])))\n",
        "pipelines.append(('RF-norm', Pipeline([min_max_scaler, random_forest])))\n",
        "pipelines.append(('ET-norm', Pipeline([min_max_scaler, extra_trees])))\n",
        "pipelines.append(('Ada-norm', Pipeline([min_max_scaler, adaboost])))\n",
        "pipelines.append(('GB-norm', Pipeline([min_max_scaler, gradient_boosting])))\n",
        "pipelines.append(('Vot-norm', Pipeline([min_max_scaler, voting])))"
      ],
      "metadata": {
        "id": "Di5x4UntC46C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 - Avaliação dos modelos com dados padronizados e com dados normalizados"
      ],
      "metadata": {
        "id": "qe2t8obuU44l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Executando os pipelines\n",
        "for name, model in pipelines:\n",
        "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %.3f (%.3f)\" % (name, cv_results.mean(), cv_results.std()) # formatando para 3 casas decimais\n",
        "    print(msg)\n",
        "\n",
        "# Boxplot de comparação dos modelos\n",
        "fig = plt.figure(figsize=(25,6))\n",
        "fig.suptitle('Comparação dos Modelos - Dataset orginal, padronizado e normalizado')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names, rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tK1E_4neUxiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Observação: Não foi feita a otimização de hiperparâmetros porque a acurácia do modelo (GradientBoostingClassifier-Original) é aproximadamente de 97%. O que justifica essa decisão."
      ],
      "metadata": {
        "id": "sNnMFH6rVk1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Avaliação de Resultados\n",
        "\n",
        "## 4.1 - Avaliação do melhor modelo (GradientBoostingClassifier) no Conjunto de Testes\n",
        "\n"
      ],
      "metadata": {
        "id": "lMfqKJNaCRFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação do modelo com o conjunto de testes\n",
        "\n",
        "# Preparação do modelo\n",
        "scaler = StandardScaler().fit(X_train) # ajuste do scaler com o conjunto de treino\n",
        "rescaledX = scaler.transform(X_train) # aplicação da padronização no conjunto de treino\n",
        "model = GradientBoostingClassifier(n_estimators=num_trees)\n",
        "model.fit(rescaledX, Y_train)\n",
        "\n",
        "# Estimativa da acurácia no conjunto de teste\n",
        "rescaledTestX = scaler.transform(X_test) # aplicação da padronização no conjunto de teste\n",
        "predictions = model.predict(rescaledTestX)\n",
        "print(accuracy_score(Y_test, predictions))"
      ],
      "metadata": {
        "id": "ddaXMnRGsvRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 - Avaliação do melhor modelo"
      ],
      "metadata": {
        "id": "n11RsD4HWzTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparação do modelo com TODO o dataset\n",
        "scaler = StandardScaler().fit(X) # ajuste do scaler com TODO o dataset\n",
        "rescaledX = scaler.transform(X) # aplicação da padronização com TODO o dataset\n",
        "model.fit(rescaledX, Y)"
      ],
      "metadata": {
        "id": "500gzVweuYoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 - Novos dados para teste com o modelo GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "MZh9b0BbW0MC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Novos dados - não sabemos a classe!\n",
        "data = {'num_inscricao':  [901, 902, 903, 904, 905, 906, 907, 908, 909, 910],\n",
        "        'nota_mat': [90, 65, 85, 77, 86, 91, 75, 98, 93, 81],\n",
        "        'nota_linguagens': [95, 79, 83, 71, 59, 88, 86, 77, 85, 82],\n",
        "        'nota_ciencias_hum': [92, 81, 86, 92, 61, 97, 92, 99, 90, 83],\n",
        "        'nota_ciencias_nat': [100, 64, 84, 98, 72, 99, 78, 72, 77, 84],\n",
        "        'nota_redacao': [94, 90, 95, 99, 53, 86, 79, 95, 78, 79],\n",
        "        'renda_fam_per_capita': [1500, 1300, 1200, 1180, 1700, 1800, 980, 1020, 1650, 1010],\n",
        "        'premio_olimp_conhecimento': [1, 0, 1, 0, 0, 1, 0, 1, 1, 0],\n",
        "        'prog_social_gov': [0, 0, 0, 1, 0, 0, 1, 1, 0, 0],\n",
        "        }\n",
        "\n",
        "atributos = ['num_inscricao', 'nota_mat', 'nota_linguagens', 'nota_ciencias_hum', 'nota_ciencias_nat', 'nota_redacao', 'renda_fam_per_capita', 'premio_olimp_conhecimento', 'prog_social_gov']\n",
        "entrada = pd.DataFrame(data, columns=atributos)\n",
        "\n",
        "array_entrada = entrada.values\n",
        "X_entrada = array_entrada[:,0:9].astype(float)\n",
        "\n",
        "# Padronização nos dados de entrada usando o scaler utilizado em X\n",
        "rescaledEntradaX = scaler.transform(X_entrada)\n",
        "print(rescaledEntradaX)"
      ],
      "metadata": {
        "id": "7aKO1sKUu9QB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 - Predição com o modelo GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "fvOb_g7iXLlY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predição de classes dos dados de entrada\n",
        "saidas = model.predict(rescaledEntradaX)\n",
        "print(saidas)"
      ],
      "metadata": {
        "id": "0EkrXqqzu_O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Considerações Finais: Comparando os resultados de diferentes modelos, podemos observar que o modelo GradientBoostingClassifier(Original) foi o melhor com acurácia de aproximadamente 97%. Esse modelo obteve praticamente os mesmos (e melhores) valores com a padronização e com a normalização. Não foi verificado overfiting nem underfiting. Após o treinamento do modelo GradientBoostingClassifier, ele foi utilizado com toda a base de treino, com a base de teste e com todo o dataset."
      ],
      "metadata": {
        "id": "hTJw1ZYqXh2e"
      }
    }
  ]
}